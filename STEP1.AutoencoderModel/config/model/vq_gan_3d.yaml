seed: 1234
num_workers: 8

gpus: [2, 3, 4, 5]
accumulate_grad_batches: 2 #1
default_root_dir: checkpoints/vq_gan/
default_root_dir_postfix: AutoPET_with_val # testing # '8k_96_d4_steplr'
resume: False
resume_version: 0
resume_from_checkpoint: ~ #checkpoints/vq_gan/synt/AutoPET/lightning_logs/version_7/checkpoints/epoch=41-step=9000-train/recon_loss=0.30.ckpt #checkpoints/vq_gan/synt/testing/lightning_logs/version_9/checkpoints/epoch=6-step=21500-train/recon_loss=0.34.ckpt #~
pretrained_checkpoint: ../../DiffTumor_data/AutoencoderModel.ckpt #~
max_steps: 100000 #160000 #80000
max_epochs: -1
precision: 16
gradient_clip_val: 1.0

embedding_dim: 8
n_codes: 16384
n_hiddens: 16
lr: 3e-4
downsample: [4, 4, 4]
disc_channels: 64
disc_layers: 3
discriminator_iter_start: 10000 #, 1 just for debugging
disc_loss_type: hinge
image_gan_weight: 1.0
video_gan_weight: 1.0
l1_weight: 4.0
gan_feat_weight: 4.0
perceptual_weight: 4.0 
i3d_feat: False
restart_thres: 1.0
no_random_restart: False
norm_type: group
padding_type: replicate
num_groups: 16 # 32 needs to change in ratio with the number of channels, in turn n_hiddens
